{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import r2_score\n",
    "import sys\n",
    "from rfpimp import importances\n",
    "from rfpimp import dropcol_importances\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.api.types import is_bool_dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df = '../gene_info.full_model.rice_blast.txt'\n",
    "majority_fraction =  0.5 ## just to get trues and falses balanced well\n",
    "approach = 'RF'\n",
    "n_estimators = 500\n",
    "min_samples_split =  2\n",
    "min_samples_leaf = 1\n",
    "max_features = 'None'\n",
    "max_depth = 'None'\n",
    "bootstrap = 'True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def none_or_str(value):\n",
    "    if value == 'None':\n",
    "        return None\n",
    "    return value\n",
    "\n",
    "max_features = none_or_str(max_features)\n",
    "\n",
    "\n",
    "def none_or_int(value):\n",
    "    if value == 'None':\n",
    "        return None\n",
    "    return int(value)\n",
    "\n",
    "max_depth = none_or_int(max_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_dict = {\n",
    "    \"n_estimators\": n_estimators,\n",
    "    \"min_samples_split\": min_samples_split,\n",
    "    \"min_samples_leaf\": min_samples_leaf,\n",
    "    \"max_features\": max_features,\n",
    "    \"max_depth\": max_depth,\n",
    "    \"bootstrap\": bootstrap\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reports(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    TP = len(y_pred[(y_pred == 1) & (y_test == 1)])\n",
    "    FN = len(y_pred[(y_pred == 0) & (y_test == 1)])\n",
    "    FP = len(y_pred[(y_pred == 1) & (y_test == 0)])\n",
    "    # sensitivity, how sensitive is the test? TP/TP+FN aka recall\n",
    "    recall = TP/(TP+FN)\n",
    "    ## PPV, how powerful is a positive? TP/TP+FP aka precision\n",
    "    precision = TP/(TP+FP)\n",
    "    ap = average_precision_score(y_test, model.predict_proba(X_test)[:,1])\n",
    "    auc = roc_auc_score(y_test, model.predict_proba(X_test)[:,1])\n",
    "    return([recall, precision, ap, auc])\n",
    "\n",
    "def train_test_split_mine_downsample(majority_fraction):\n",
    "    df_genes = pd.read_csv(input_df)\n",
    "    df_genes = df_genes[df_genes['lineage']!=4]\n",
    "    ## pick 4 genomes per lineage as testing data\n",
    "    genome_test_subset = []\n",
    "    for lineage in np.unique(df_genes.lineage):\n",
    "        for genome in np.random.choice(df_genes[df_genes.lineage == lineage].genome, size=4,replace=False):\n",
    "            genome_test_subset.append(genome)\n",
    "    df_genes_test_subset = df_genes[df_genes.genome.isin(genome_test_subset)]\n",
    "    df_genes = df_genes[~df_genes.genome.isin(genome_test_subset)]\n",
    "    if majority_fraction != 1.0:\n",
    "        pav_true_subset = df_genes[df_genes['lineage_pav']==True].id\n",
    "        pav_false_subset_downsampled = np.random.choice(df_genes[df_genes['lineage_pav'] == False].id, size=int(len(df_genes.index)*majority_fraction),replace=False)\n",
    "        df_genes_downsampled = df_genes[(df_genes.id.isin(pav_false_subset_downsampled)) | (df_genes.id.isin(pav_true_subset))]\n",
    "    else:\n",
    "        df_genes_downsampled = df_genes\n",
    "    # drop columns\n",
    "    df_genes_downsampled = df_genes_downsampled.drop(['id', 'scaffold', 'start', 'end', 'orientation', 'orthogroups', 'enough_space_te', 'enough_space_gene',\n",
    "                            'genome', 'lineage', 'lineage_conserved', 'proportion'], axis=1)\n",
    "    df_genes_test_subset = df_genes_test_subset.drop(['id', 'scaffold', 'start', 'end', 'orientation', 'orthogroups', 'enough_space_te', 'enough_space_gene',\n",
    "                            'genome', 'lineage', 'lineage_conserved', 'proportion'], axis=1)\n",
    "    y_train = df_genes_downsampled['lineage_pav']\n",
    "    X_train = df_genes_downsampled.drop('lineage_pav', axis=1)\n",
    "    y_test = df_genes_test_subset['lineage_pav']\n",
    "    X_test = df_genes_test_subset.drop('lineage_pav', axis=1)\n",
    "    return(y_train,X_train,y_test,X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train,X_train,y_test,X_test = train_test_split_mine_downsample(majority_fraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if approach == \"SMOTE\":\n",
    "    oversample = SMOTE()\n",
    "    over_X_train, over_y_train = oversample.fit_resample(X_train, y_train)\n",
    "    X_train = over_X_train\n",
    "    y_train = over_y_train\n",
    "if approach == \"BRFC\":\n",
    "    model = BalancedRandomForestClassifier(**args_dict)\n",
    "elif approach == \"RF_balanced\":\n",
    "    model = RandomForestClassifier(class_weight=\"balanced\", **args_dict)\n",
    "elif approach == \"RF_balanced_subsample\":\n",
    "    model = RandomForestClassifier(class_weight=\"balanced_subsample\", **args_dict)\n",
    "elif approach == \"RF\":\n",
    "    model = RandomForestClassifier(**args_dict)\n",
    "elif approach == \"SMOTE\":\n",
    "    model = RandomForestClassifier(**args_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(bootstrap=&#x27;True&#x27;, max_features=None, n_estimators=500)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(bootstrap=&#x27;True&#x27;, max_features=None, n_estimators=500)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(bootstrap='True', max_features=None, n_estimators=500)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## dont need to train just load the pkl\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_calc_mine(model, X_valid, y_valid):\n",
    "    y_pred = model.predict(X_valid)\n",
    "    f1 = f1_score(y_valid,y_pred)\n",
    "    return(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8599146294140473\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "baseline = f1_score(y_test, y_pred)\n",
    "permuted_f1s = []\n",
    "column = 'any_te'\n",
    "save = X_test[column].copy()\n",
    "X_test[column] = np.random.permutation(X_test[column])\n",
    "y_pred = model.predict(X_test)\n",
    "permuted_f1 = f1_score(y_test, y_pred)\n",
    "permuted_f1s.append(permuted_f1)\n",
    "X_test[column] = save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6505066560699383]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "permuted_f1s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "baseline = f1_score(y_test, y_pred)\n",
    "permuted_diffs = []\n",
    "for column in X_test.columns:\n",
    "    save = X_test[column].copy()\n",
    "    X_test[column] = np.random.permutation(X_test[column])\n",
    "    y_pred = model.predict(X_test)\n",
    "    permuted_f1 = f1_score(y_test, y_pred)\n",
    "    diff = baseline-permuted_f1\n",
    "    permuted_diffs.append(diff)\n",
    "    X_test[column] = save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['any_te', 'gene_nearby', 'gene_gc', 'flanking_1kb_gc', 'lengths', 'tm',\n",
       "       'signalp', 'effectorp', 'H3K27ac', 'H3K27me3', 'H3K36me3',\n",
       "       'cm_expression', 'ip_expression', 'eccdna_cov', 'methylation', 'go',\n",
       "       'pfam'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "any_te\tgene_nearby\tgene_gc\tflanking_1kb_gc\tlengths\ttm\tsignalp\teffectorp\tH3K27ac\tH3K27me3\tH3K36me3\tcm_expression\tip_expression\teccdna_cov\tmethylation\tgo\tpfam\n"
     ]
    }
   ],
   "source": [
    "print('\\t'.join(X_test.columns.to_list()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "any_te\n",
      "0.20089024937150612\n",
      "gene_nearby\n",
      "0.04455532369490389\n",
      "gene_gc\n",
      "0.004137505238245076\n",
      "flanking_1kb_gc\n",
      "0.20245512537807886\n",
      "lengths\n",
      "0.29491980850163546\n",
      "tm\n",
      "0.034092563855527946\n",
      "signalp\n",
      "0.012083373785501395\n",
      "effectorp\n",
      "0.0056992487967253425\n",
      "H3K27ac\n",
      "0.08593627577060947\n",
      "H3K27me3\n",
      "0.6718168558189677\n",
      "H3K36me3\n",
      "0.17850379302572805\n",
      "cm_expression\n",
      "0.0643617502429823\n",
      "ip_expression\n",
      "0.06016204232702016\n",
      "eccdna_cov\n",
      "0.06618593454910782\n",
      "methylation\n",
      "0.08531626651499824\n",
      "go\n",
      "0.0769397406804756\n",
      "pfam\n",
      "0.17421185352302804\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(X_test.columns)):\n",
    "    print(X_test.columns[i])\n",
    "    print(permuted_diffs[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_dict = dict(zip(X_test.columns.to_list(), permuted_diffs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'any_te': 0.20089024937150612,\n",
       " 'gene_nearby': 0.04455532369490389,\n",
       " 'gene_gc': 0.004137505238245076,\n",
       " 'flanking_1kb_gc': 0.20245512537807886,\n",
       " 'lengths': 0.29491980850163546,\n",
       " 'tm': 0.034092563855527946,\n",
       " 'signalp': 0.012083373785501395,\n",
       " 'effectorp': 0.0056992487967253425,\n",
       " 'H3K27ac': 0.08593627577060947,\n",
       " 'H3K27me3': 0.6718168558189677,\n",
       " 'H3K36me3': 0.17850379302572805,\n",
       " 'cm_expression': 0.0643617502429823,\n",
       " 'ip_expression': 0.06016204232702016,\n",
       " 'eccdna_cov': 0.06618593454910782,\n",
       " 'methylation': 0.08531626651499824,\n",
       " 'go': 0.0769397406804756,\n",
       " 'pfam': 0.17421185352302804}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.DataFrame(df_test_dict, index=['1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.loc[len(df_test.index)] = [1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_means_dict = dict(zip(X_test.columns.to_list(), df_test.mean()))\n",
    "df_means_test = pd.DataFrame(df_means_dict, index=['1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>any_te</th>\n",
       "      <th>gene_nearby</th>\n",
       "      <th>gene_gc</th>\n",
       "      <th>flanking_1kb_gc</th>\n",
       "      <th>lengths</th>\n",
       "      <th>tm</th>\n",
       "      <th>signalp</th>\n",
       "      <th>effectorp</th>\n",
       "      <th>H3K27ac</th>\n",
       "      <th>H3K27me3</th>\n",
       "      <th>H3K36me3</th>\n",
       "      <th>cm_expression</th>\n",
       "      <th>ip_expression</th>\n",
       "      <th>eccdna_cov</th>\n",
       "      <th>methylation</th>\n",
       "      <th>go</th>\n",
       "      <th>pfam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.20089</td>\n",
       "      <td>0.044555</td>\n",
       "      <td>0.004138</td>\n",
       "      <td>0.202455</td>\n",
       "      <td>0.29492</td>\n",
       "      <td>0.034093</td>\n",
       "      <td>0.012083</td>\n",
       "      <td>0.005699</td>\n",
       "      <td>0.085936</td>\n",
       "      <td>0.671817</td>\n",
       "      <td>0.178504</td>\n",
       "      <td>0.064362</td>\n",
       "      <td>0.060162</td>\n",
       "      <td>0.066186</td>\n",
       "      <td>0.085316</td>\n",
       "      <td>0.07694</td>\n",
       "      <td>0.174212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    any_te  gene_nearby   gene_gc  flanking_1kb_gc  lengths        tm  \\\n",
       "1  0.20089     0.044555  0.004138         0.202455  0.29492  0.034093   \n",
       "1  1.00000     1.000000  1.000000         1.000000  1.00000  1.000000   \n",
       "\n",
       "    signalp  effectorp   H3K27ac  H3K27me3  H3K36me3  cm_expression  \\\n",
       "1  0.012083   0.005699  0.085936  0.671817  0.178504       0.064362   \n",
       "1  1.000000   1.000000  1.000000  1.000000  1.000000       1.000000   \n",
       "\n",
       "   ip_expression  eccdna_cov  methylation       go      pfam  \n",
       "1       0.060162    0.066186     0.085316  0.07694  0.174212  \n",
       "1       1.000000    1.000000     1.000000  1.00000  1.000000  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>any_te</th>\n",
       "      <th>gene_nearby</th>\n",
       "      <th>gene_gc</th>\n",
       "      <th>flanking_1kb_gc</th>\n",
       "      <th>lengths</th>\n",
       "      <th>tm</th>\n",
       "      <th>signalp</th>\n",
       "      <th>effectorp</th>\n",
       "      <th>H3K27ac</th>\n",
       "      <th>H3K27me3</th>\n",
       "      <th>H3K36me3</th>\n",
       "      <th>cm_expression</th>\n",
       "      <th>ip_expression</th>\n",
       "      <th>eccdna_cov</th>\n",
       "      <th>methylation</th>\n",
       "      <th>go</th>\n",
       "      <th>pfam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.600445</td>\n",
       "      <td>0.522278</td>\n",
       "      <td>0.502069</td>\n",
       "      <td>0.601228</td>\n",
       "      <td>0.64746</td>\n",
       "      <td>0.517046</td>\n",
       "      <td>0.506042</td>\n",
       "      <td>0.50285</td>\n",
       "      <td>0.542968</td>\n",
       "      <td>0.835908</td>\n",
       "      <td>0.589252</td>\n",
       "      <td>0.532181</td>\n",
       "      <td>0.530081</td>\n",
       "      <td>0.533093</td>\n",
       "      <td>0.542658</td>\n",
       "      <td>0.53847</td>\n",
       "      <td>0.587106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     any_te  gene_nearby   gene_gc  flanking_1kb_gc  lengths        tm  \\\n",
       "1  0.600445     0.522278  0.502069         0.601228  0.64746  0.517046   \n",
       "\n",
       "    signalp  effectorp   H3K27ac  H3K27me3  H3K36me3  cm_expression  \\\n",
       "1  0.506042    0.50285  0.542968  0.835908  0.589252       0.532181   \n",
       "\n",
       "   ip_expression  eccdna_cov  methylation       go      pfam  \n",
       "1       0.530081    0.533093     0.542658  0.53847  0.587106  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_means_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## okay now to make the dependence matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cols = [col for col in X_train]\n",
    "boolcols = [col for col in X_train if is_bool_dtype(X_train[col])]\n",
    "df_dep = pd.DataFrame(index=X_train.columns, columns=['Dependence']+X_train.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, dep_feature in enumerate(all_cols):\n",
    "    row = []\n",
    "    X_dep_train, y_dep_train = X_train.drop(dep_feature, axis=1), X_train[dep_feature]\n",
    "    X_dep_test, y_dep_test = X_test.drop(dep_feature, axis=1), X_test[dep_feature]\n",
    "    if dep_feature in boolcols:\n",
    "        model_dep = RandomForestClassifier(**args_dict)\n",
    "    else:\n",
    "        model_dep = RandomForestRegressor(**args_dict)\n",
    "    model_dep.fit(X_dep_train,y_dep_train)\n",
    "    y_dep_pred = model.predict(X_dep_test)\n",
    "    if dep_feature in boolcols:\n",
    "        baseline = f1_score(y_dep_test, y_dep_pred)\n",
    "    else:\n",
    "        baseline = r2_score(y_dep_test, y_dep_pred)\n",
    "    row.append(baseline)\n",
    "    for perm_feature in X_dep_test.columns:\n",
    "        save = X_dep_test[perm_feature].copy()\n",
    "        X_dep_test[perm_feature] = np.random.permutation(X_dep_test[perm_feature])\n",
    "        y_dep_pred_permuted = model.predict(X_dep_test)\n",
    "        if dep_feature in boolcols:\n",
    "            permuted_score = f1_score(y_dep_test, y_dep_pred_permuted)\n",
    "        else:\n",
    "            permuted_score = f1_score(y_dep_test, y_dep_pred_permuted)\n",
    "        diff = baseline-permuted_score\n",
    "        row.append(diff)\n",
    "        X_dep_test[perm_feature] = save\n",
    "    df_dep.iloc[i] = row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_dep_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\pierr\\Box\\Krasileva_Lab\\Research\\pierre\\pav_project\\data_analysis\\pav_newest_gladieux_only_fungap\\random_forest\\importances_attempts\\importances_w_f1.ipynb Cell 28\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/pierr/Box/Krasileva_Lab/Research/pierre/pav_project/data_analysis/pav_newest_gladieux_only_fungap/random_forest/importances_attempts/importances_w_f1.ipynb#X50sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/pierr/Box/Krasileva_Lab/Research/pierre/pav_project/data_analysis/pav_newest_gladieux_only_fungap/random_forest/importances_attempts/importances_w_f1.ipynb#X50sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     model_dep \u001b[39m=\u001b[39m RandomForestRegressor(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39margs_dict)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/pierr/Box/Krasileva_Lab/Research/pierre/pav_project/data_analysis/pav_newest_gladieux_only_fungap/random_forest/importances_attempts/importances_w_f1.ipynb#X50sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m model_dep\u001b[39m.\u001b[39;49mfit(X_dep_train,y_dep_train)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/pierr/Box/Krasileva_Lab/Research/pierre/pav_project/data_analysis/pav_newest_gladieux_only_fungap/random_forest/importances_attempts/importances_w_f1.ipynb#X50sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m y_dep_pred \u001b[39m=\u001b[39m model_dep\u001b[39m.\u001b[39mpredict(X_dep_test)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/pierr/Box/Krasileva_Lab/Research/pierre/pav_project/data_analysis/pav_newest_gladieux_only_fungap/random_forest/importances_attempts/importances_w_f1.ipynb#X50sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mif\u001b[39;00m dep_feature \u001b[39min\u001b[39;00m boolcols:\n",
      "File \u001b[1;32mc:\\Users\\pierr\\.conda\\envs\\imbalanced_learn\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:476\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    465\u001b[0m trees \u001b[39m=\u001b[39m [\n\u001b[0;32m    466\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_estimator(append\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, random_state\u001b[39m=\u001b[39mrandom_state)\n\u001b[0;32m    467\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    468\u001b[0m ]\n\u001b[0;32m    470\u001b[0m \u001b[39m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    471\u001b[0m \u001b[39m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    472\u001b[0m \u001b[39m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    473\u001b[0m \u001b[39m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    474\u001b[0m \u001b[39m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    475\u001b[0m \u001b[39m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 476\u001b[0m trees \u001b[39m=\u001b[39m Parallel(\n\u001b[0;32m    477\u001b[0m     n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs,\n\u001b[0;32m    478\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[0;32m    479\u001b[0m     prefer\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mthreads\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    480\u001b[0m )(\n\u001b[0;32m    481\u001b[0m     delayed(_parallel_build_trees)(\n\u001b[0;32m    482\u001b[0m         t,\n\u001b[0;32m    483\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbootstrap,\n\u001b[0;32m    484\u001b[0m         X,\n\u001b[0;32m    485\u001b[0m         y,\n\u001b[0;32m    486\u001b[0m         sample_weight,\n\u001b[0;32m    487\u001b[0m         i,\n\u001b[0;32m    488\u001b[0m         \u001b[39mlen\u001b[39;49m(trees),\n\u001b[0;32m    489\u001b[0m         verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[0;32m    490\u001b[0m         class_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclass_weight,\n\u001b[0;32m    491\u001b[0m         n_samples_bootstrap\u001b[39m=\u001b[39;49mn_samples_bootstrap,\n\u001b[0;32m    492\u001b[0m     )\n\u001b[0;32m    493\u001b[0m     \u001b[39mfor\u001b[39;49;00m i, t \u001b[39min\u001b[39;49;00m \u001b[39menumerate\u001b[39;49m(trees)\n\u001b[0;32m    494\u001b[0m )\n\u001b[0;32m    496\u001b[0m \u001b[39m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    497\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_\u001b[39m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32mc:\\Users\\pierr\\.conda\\envs\\imbalanced_learn\\lib\\site-packages\\joblib\\parallel.py:1046\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1043\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1044\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1046\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[0;32m   1047\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[0;32m   1049\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   1050\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1051\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1052\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pierr\\.conda\\envs\\imbalanced_learn\\lib\\site-packages\\joblib\\parallel.py:861\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    859\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    860\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 861\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[0;32m    862\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pierr\\.conda\\envs\\imbalanced_learn\\lib\\site-packages\\joblib\\parallel.py:779\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    777\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    778\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[1;32m--> 779\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[0;32m    780\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    781\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    782\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    783\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    784\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mc:\\Users\\pierr\\.conda\\envs\\imbalanced_learn\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m     \u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32mc:\\Users\\pierr\\.conda\\envs\\imbalanced_learn\\lib\\site-packages\\joblib\\_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    569\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[0;32m    570\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    571\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 572\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[1;32mc:\\Users\\pierr\\.conda\\envs\\imbalanced_learn\\lib\\site-packages\\joblib\\parallel.py:262\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    259\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 262\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    263\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\pierr\\.conda\\envs\\imbalanced_learn\\lib\\site-packages\\joblib\\parallel.py:262\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    259\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 262\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    263\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\pierr\\.conda\\envs\\imbalanced_learn\\lib\\site-packages\\sklearn\\utils\\fixes.py:117\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    116\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig):\n\u001b[1;32m--> 117\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\pierr\\.conda\\envs\\imbalanced_learn\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:189\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[39melif\u001b[39;00m class_weight \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbalanced_subsample\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    187\u001b[0m         curr_sample_weight \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m compute_sample_weight(\u001b[39m\"\u001b[39m\u001b[39mbalanced\u001b[39m\u001b[39m\"\u001b[39m, y, indices\u001b[39m=\u001b[39mindices)\n\u001b[1;32m--> 189\u001b[0m     tree\u001b[39m.\u001b[39;49mfit(X, y, sample_weight\u001b[39m=\u001b[39;49mcurr_sample_weight, check_input\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    190\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    191\u001b[0m     tree\u001b[39m.\u001b[39mfit(X, y, sample_weight\u001b[39m=\u001b[39msample_weight, check_input\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\pierr\\.conda\\envs\\imbalanced_learn\\lib\\site-packages\\sklearn\\tree\\_classes.py:969\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    939\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, check_input\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m    940\u001b[0m     \u001b[39m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[0;32m    941\u001b[0m \n\u001b[0;32m    942\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    966\u001b[0m \u001b[39m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m    967\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 969\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m    970\u001b[0m         X,\n\u001b[0;32m    971\u001b[0m         y,\n\u001b[0;32m    972\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m    973\u001b[0m         check_input\u001b[39m=\u001b[39;49mcheck_input,\n\u001b[0;32m    974\u001b[0m     )\n\u001b[0;32m    975\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\pierr\\.conda\\envs\\imbalanced_learn\\lib\\site-packages\\sklearn\\tree\\_classes.py:458\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    447\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    448\u001b[0m     builder \u001b[39m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    449\u001b[0m         splitter,\n\u001b[0;32m    450\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    455\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    456\u001b[0m     )\n\u001b[1;32m--> 458\u001b[0m builder\u001b[39m.\u001b[39;49mbuild(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtree_, X, y, sample_weight)\n\u001b[0;32m    460\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m is_classifier(\u001b[39mself\u001b[39m):\n\u001b[0;32m    461\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_[\u001b[39m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "dep_feature = all_cols[0]\n",
    "row = []\n",
    "X_dep_train, y_dep_train = X_train.drop(dep_feature, axis=1), X_train[dep_feature]\n",
    "X_dep_test, y_dep_test = X_test.drop(dep_feature, axis=1), X_test[dep_feature]\n",
    "if dep_feature in boolcols:\n",
    "    model_dep = RandomForestClassifier(**args_dict)\n",
    "else:\n",
    "    model_dep = RandomForestRegressor(**args_dict)\n",
    "model_dep.fit(X_dep_train,y_dep_train)\n",
    "y_dep_pred = model_dep.predict(X_dep_test)\n",
    "if dep_feature in boolcols:\n",
    "    baseline = f1_score(y_dep_test, y_dep_pred)\n",
    "else:\n",
    "    baseline = r2_score(y_dep_test, y_dep_pred)\n",
    "row.append(baseline)\n",
    "for perm_feature in X_dep_test.columns:\n",
    "    if perm_feature == dep_feature:\n",
    "        row.append('x')\n",
    "        continue\n",
    "    save = X_dep_test[perm_feature].copy()\n",
    "    X_dep_test[perm_feature] = np.random.permutation(X_dep_test[perm_feature])\n",
    "    y_dep_pred_permuted = model_dep.predict(X_dep_test)\n",
    "    if dep_feature in boolcols:\n",
    "        permuted_score = f1_score(y_dep_test, y_dep_pred_permuted)\n",
    "    else:\n",
    "        permuted_score = f1_score(y_dep_test, y_dep_pred_permuted)\n",
    "    diff = baseline-permuted_score\n",
    "    row.append(diff)\n",
    "    X_dep_test[perm_feature] = save\n",
    "df_dep.iloc[i] = row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8592623550308223, 0.07858404053955814, 0.00010815990123991259, 0.11320917680066023, 0.09759387929815044, 0.007995370087744758, 0.012703181250655615, 0.0006252544607683319, 0.06596315645557749, 0.6308228453292887, 0.0960935882470999, 0.031573165120950764, 0.03799331676592799, 0.031934625738109346, 0.06344632009255746, 0.021870691803418163, 0.018138933232316745]\n"
     ]
    }
   ],
   "source": [
    "print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('imbalanced_learn')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c2315821898a4f1de250b11175021d0bad67aa42c758ebaa32223c2f00dcd7fb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
